<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Fluorescence Diffractive Tomography with Neural Fields</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon2.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
<!--   <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .column.content img {
      width: 100%;
      height: auto;
    }
    .caption {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text .section-title {
      font-weight: bold;
      font-style: italic;
    }
  </style>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Fluorescence Diffractive Tomography with Neural Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Renzhi He</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Yucheng Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Junjie Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Yi Xue</a><sup>2</sup>,
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Davis,</span>
<!--             <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">



  
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Solving the 3D refractive index (RI) from fluorescence images provides both fluorescence 
            and phase information about biological samples. However, accurately retrieving the phase of 
            partially coherent light to reconstruct the unknown RI of label-free objects over a large volume 
            at high-resolution in the reflection mode remain challenging. 
          </p>
          <p>
            Thus, we developed fluorescence diffraction tomography (FDT) with explicit neural fields 
            that can reconstruct 3D RI from defocused fluorescence images. We also develop many power tools 
            like the coarse-to-fine modeling, self-calibration, differential multi-slice rendering model, 
            and partial coherent mask to facilitate the functionality of the FDT. The explicit representation 
            efficiently integrates with coarse-to-fine modeling to achieve high-speed, high-resolution reconstruction. 
            Moreover, we advance the multi-slice equation to differential multi-slice rendering model which enables 
            the self-calibration method for the extrinsic and intrinsic parameters of the system to achieve high accuracy
            forward image prediction and RI reconstruction. To address the model discrepancies between the coherent light-based 
            model and the partial coherent light source, we develop digital masks instead of modeling 
            the partial coherent light source, which is more computationally efficient. 
          </p>
          <p>  
            Our method successfully reconstructed label-free 3D muscle cells in a 530 × 530 × 300 µm<span class="superscript">3</span> volume 
            at 1024×1024 pixels across 24 layers from fluorescence images. FDT achieves high fidelity 3D RI reconstruction 
            of bulky and heterogeneous biological samples.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Overview</h2>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/fig.overview.jpg" alt="Matting Example" style="width: 100%; height: auto;">
            <p class="caption">
              Fig. 1 Overview pipeline of the neural fields reconstruction method.
            </p>
            <p>
              <span class="caption">a</span>, The refractive index (RI) is generated by the neural fields model and refined through three stages with increasing resolutions at different iterations using a coarse-to-fine structure. 
              <span class="caption">b</span>, Self-calibration is applied to the illumination position, starting from an initial estimation by Gaussian fitting. The values are then set as iterative parameters and optimized during the training process. 
              <span class="caption">c</span>, The rendering equation is based on the differential multi-slice model, which takes two inputs: the RI from <span class="section-title">a</span> and the illumination position from <span class="section-title">b</span>. This model describes how the light propagates through free space and the RI, and captured at the image plane to form an image. 
              <span class="caption">d</span>, A partial coherent light mask is generated by the multi-slice model with an empty RI and then applied to the predicted and measured images. The masked images are used to calculate the loss function, incorporating L1, L2, SSIM, and regularization terms.
            </p>
          </div>
        </div>
      </div>
      
      <style>
        .column.content img {
          width: 100%;
          height: auto;
        }
      </style>
    </div>

    <!--/ Matting. -->



<div class="columns is-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Results</h2>

    <div class="content has-text-justified">
      <p>
        We verify the validation of our model as well as each component in the
        model under the simulation 'ucdavis' data. Then, we applied the FDT to experimental
        data of thin (MDCK) and thick (3D muscle tube) sample to show the effectiveness of our model for variety of
        structure and z-section ability. 
      </p>
      <div class="related-work">
        <div class="work-item">
          <a href="https://arxiv.org/abs/2104.09125">
            <img src="./static/images/fig.ucd.jpg" alt="Progressive Encoding for Neural Optimization">
          </a>
          <p class="caption">Reconstruction of simulated ``UCDavis" pattern.</p>
          <p>
            <span class="caption">a</span>, 3D refractive index (RI) distribution in 3D space. 
            <span class="caption">b</span>, Ground-truth (GT) image and a magnified view of the region within the orange box, generated by the multi-slice model using the known 3D RI. 
            <span class="caption">c</span>, Predicted image and a magnified view of the region within the green box, generated by our EXPORT method. The mean squared error (MSE) and structural similarity index (SSIM) between the ground-truth and predicted images are indicated. 
            <span class="caption">d</span>, RI comparison for each layer: the first row shows the ground-truth RI for each layer, and the second row shows the RI predicted by our method. The axes indicate the location along the z-direction.
          </p>
        </div>
        <div class="work-item">
          <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">
            <img src="./static/images/fig.mdck.jpg" alt="D-NeRF">
          </a>
          <p class="caption">3D RI Reconstruction of a MDCK sample.</p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI distribution within a volume of 358.4 x 358.4 x 60 $\mu m^3$ . 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images, with a highlighted region of interest. 
            <span class="caption">c</span>, Detailed views of the highlighted region: measured image (top), predicted image (middle), and error map (bottom). 
            <span class="caption">d-f</span>, Cross-sectional views of the RI difference  distribution along different planes ($xy$, $xz$, $yz$), illustrating spatial variations in RI. 
            <span class="caption">g</span>, Quantitative analysis of RI variation of the red box in \textbf{d}, showing RI along the X-axis (top) and Z-axis (bottom). 
            <span class="caption">h</span>, Sequence of images highlighting the appearance and disappearance of specific features within the region along the Z-axis.
          </p>
        </div>
        <div class="work-item">
          <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">
            <img src="./static/images/fig.tube.jpg" alt="NR-NeRF">
          </a>
          <p class="caption">3D RI Reconstruction of a 3D muscle sample.</p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI distribution within a volume of $530 \times 530 \times 300 \mu m^3$. 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images, highlighting a region of interest. 
            <span class="caption">c-d</span>, Cross-sectional views of the RI difference distribution along different planes ($xy$, $xz$, $yz$), illustrating spatial variations in RI. 
            <span class="caption">e</span>, Zoomed-in details of the highlighted regions in \textbf{c} and \textbf{d}, showing three different morphological fine structures and variations in RI: 
            the top image corresponds to the green box in (d), the middle image to the orange box in (d), and the bottom image to the red box in (c).</p>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
  .related-work {
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  .work-item {
    text-align: center;
    margin-bottom: 20px;
    width: 100%;
  }
  .work-item img {
    display: block;
    margin: 0 auto;
    width: 100%;
    height: auto;
  }
  .caption {
    font-weight: bold;
    margin-top: 10px;
  }
</style>



    
    <!-- Concurrent Work. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

    <!-- Animation. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
<!--         <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
<!--         <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->

  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<!--     <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre> -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
