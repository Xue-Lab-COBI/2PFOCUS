<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy">
  <meta name="keywords" content="Scattering correction, Open channel, Two-photon microscopy, Deep tissue imaging">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
 
    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon2.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
<!--   <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .column.content img {
      width: 100%;
      height: auto;
    }
    .caption {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text .section-title {
      font-weight: bold;
      font-style: italic;
    }
    .scientific-notation {
      font-family: 'Times New Roman', Times, serif;
      font-style: italic;
    }
    .superscript {
      vertical-align: super;
      font-size: smaller;
    }
  </style>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Daniel Zepeda</a>,</span>
            <span class="author-block">
              <a href="">Yucheng Li</a>,</span>
            <span class="author-block">
              <a href="https://cobi.ucdavis.edu/people">Yi Xue*</a>,
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of California, Davis,</span>
<!--             <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.15192"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.15192"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> 
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->




<section class="section">



  
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Light penetration depth in biological tissue is limited by tissue scattering. Correcting scattering becomes particularly challenging in scenarios with limited photon availability and when access to the transmission side of the scattering tissue is not possible. 
          </p>
          <p>  
            Here, we introduce a new two-photon microscopy system with Fourier-domain open-channel coupling for scattering correction (2P-FOCUS). 2P-FOCUS corrects scattering by intensity modulation in the Fourier domain, leveraging the nonlinearity of multiple-beam interference and two-photon excitation, eliminating the need for a guide star, iterative optimization, or measuring transmission or reflection matrices. 2P-FOCUS can also correct scattering beyond the limitation of the memory effect by automatically customizing correction masks for each subregion in a large field-of-view. 
          </p>
          <p>  
            We provide several proof-of-principle demonstrations here, including focusing and imaging through a bone sample, and imaging neurons and cerebral blood vessels in the mouse brain ex vivo. 2P-FOCUS significantly enhances two-photon fluorescence signals by several tens of folds compared to cases without scattering correction at the same excitation power. 2P-FOCUS can also correct tissue scattering over a 230 x 230 x 500 µm<span class="superscript">3</span> volume, which is beyond the memory effect range. 2P-FOCUS is able to measure, calculate, and correct scattering within a few seconds, effectively delivering more light deep into the scattering tissue. 2P-FOCUS could be broadly adopted for deep tissue imaging owing to its powerful combination of effectiveness, speed, and cost.

          </p>
        </div>
      </div>
    </div>
    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Overview</h2>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/Fig1.jpg" style="width: 100%; height: auto;">
            <p class="caption">
              <strong>Overview of 2P-Focus Principle and schematic diagram</strong>
            </p>
            <p>
              <span class="caption">a</span>, Without correction, all pixels of the digital micromirror device (DMD) are turned on, allowing all incident light to pass through to the scattering sample. The incident light is scattered and cannot form a tight focus. 
              <span class="caption">b</span>, The process of generating a correction mask involves three steps. The first step is to project random intensity patterns, which are orthogonal to each other, onto the DMD and record the corresponding fluorescence intensity using a photomultiplier tube (PMT). The second step is selecting the random masks that correspond to high fluorescence intensity and summing these masks to create a grayscale correction mask. The third step is to binarize the grayscale correction mask for display on the DMD. 
              <span class="caption">c</span>, With correction, the binary correction mask is projected on the DMD, allowing only the beams that interfere constructively pass through. The illumination power on the sample is maintained at the same level before and after correction by increasing the input power to the DMD to compensate for the power loss due to turning off some pixels. The correction results in a brighter focus compared to the case before correction. 
              <span class="caption">d</span>, Optical schematic diagram of 2P-FOCUS. A femtosecond laser at 1035 nm is used as the light source. A half-wave plate (HWP) and a polarized beam splitter (PBS) are used to control the laser power. A pair of scanning mirrors (SM) is used to scan the focus across the field-of-view. A grating is used to compensate for the spatial dispersion caused by the DMD. Three 4-<i>f</i> systems are implemented with pairs of relay lenses (L1 and L2, L3 and L4, L5 and the tube lens). DMD is located on the conjugate plane of the objective lens's (OL) back aperture. The objective lens focuses the beams on the sample and collects emitted fluorescence. Fluorescence is detected by a PMT after passing through a dichroic mirror (DM), a collection lens, and a color filter. Sample is mounted on a linear translation stage for collecting z-stack images
            </p>

          </div>
        </div>
      </div>
      
      <style>
        .column.content img {
          width: 100%;
          height: auto;
        }
      </style>
    </div>


    <!--/ Matting. -->



<div class="columns is-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Results</h2>

    <div class="content has-text-justified">
      <p>
        We demonstrate the performance of 2P-FOCUS with proof-of-principle experiments, including focusing and imaging through approximately 200 μm-thick bone,
        and imaging fluorescence-labeled neurons and blood vessels up to 500 μm deep in the mouse brain ex vivo. 2P-FOCUS achieves a 3-60 fold enhancement in fluorescence intensity
        compared to standard two-photon microscopy. 2P-FOCUS can also correct scattering beyond the memory effect range by projecting different correction masks onto corresponding subregions, achieving a 230 × 230 μm<sup>2</sup> field-of-view in all the experiments. 
        2P-FOCUS completes the entire correction process in a few seconds, including taking measurements, calculating correction masks, and projecting correction masks. 2P-FOCUS is an active scattering correction tool for focusing and imaging through highly scattering tissues.
      </p>
      <div class="related-work">
        <h3 class="title is-4">Subregion correction for imaging beyond the memory effect range</h3>
        <div class="work-item">
          <a href="">
            <img src="./static/images/Fig3.jpg">
          </a>
          <p class="caption">
            <strong>Imaging fluorescence beads through a 200 μm-thick bone beyond the memory effect range</strong>
          </p>
          <p>
            <span class="caption">a</span>, Schematic diagram of global correction. Global correction applies the same correction mask to all scanning locations during the imaging process.
            <span class="caption">b</span>, Schematic diagram of subregion correction. Subregion correction applies a different correction mask for each subregion. The scanning mirror and the DMD are synchronized to project the corresponding mask at each scanning location. 
            <span class="caption">c</span>, Schematic diagram of the sample used in this experiment. A piece of chicken bone was adhered on top of red fluorescent beads in PDMS
            <span class="caption">d-f</span>, <span class="caption">d-f</span> Imaging fluorescent beads through highly scattering bone across a 230 × 230 μm<sup>2</sup> field-of-view. The laser power on the sample is 25 mW for all three cases.
            <span class="caption">d</span>, The image taken without scattering correction.
            <span class="caption">e</span>, The image taken under global correction. The reference object is indicated by the yellow arrow. The object outside the memory effect range is invisible (indicated by the red arrow). The peak intensity improved from 9 to 26 after global correction.
            <span class="caption">f</span>, The image taken under subregion correction. With subregion correction, the previously invisible object in <span class="caption">e</span> becomes visible. The peak fluorescence intensity improved from 9 to 43 after subregion correction.
            <span class="caption">g</span>, The intensity profile of the two clusters of beads indicated by arrows in <span class="caption">d-f</span>. The distance between these two objects is 96 μm. The correction mask for imaging the left object cannot effectively correct scattering for imaging the right object, indicating the memory effect range of this region is smaller than 96 μm.
            
          </p>
        </div>
        </div>
        </div>
    </div>
  </div>
        <div class="work-item">
          <h3 class="title is-4">Imaging neurons deep in the brain</h3>
          <a href="">
            <img src="./static/images/Fig4.jpg">
          </a>
          <p class="caption">Imaging fluorescence-labeled neurons deep in the mouse brain using 2P-FOCUS.</p>
          <p>
            <span class="caption">a</span>, The volumetric view of parvalbumin (PV) interneurons expressing cell-fill tdTomato imaged by 2P-FOCUS ex vivo. The image volume is 230 x 230 x 450 µm<span class="superscript">3</span> . 
            <span class="caption">b</span>, The top plane of the image stack is below the surface of the brain, showing the dendrites and axons of PV interneurons without correction. Illumination power is 2 mW.
            <span class="caption">c</span>, The bottom plane of the image stack, 450 µm deep from <span class="caption">b</span>, shows some cell bodies. Background is due to autofluorescence caused by fixing the brain and the dense expression of fluorescent labeling. Subregion correction is applied, and the illumination power is increased to 14 mW. 
            <span class="caption">d</span>, Schematic diagram illustrating global correction and the correction mask used for <span class="caption">e-f</span>. The same mask is used for all scanning locations. The correction mask is generated by optimizing the fluorescence intensity of the reference neuron (pointed by the yellow arrow in <span class="caption">e</span>).
            <span class="caption">e-f</span>, Images of the same region at 250 µm depth <span class="caption">e</span> before and <span class="caption">f</span> after global correction. Fluorescence intensity is improved by about 3-fold after correction. Insert: Zoomed-in view of the neurons pointed by the blue and red arrows. Scale bar, 5 µm.
            <span class="caption">g</span>, Schematic diagram for subregion correction and the four subregions in <span class="caption">h-i</span>.
            <span class="caption">h-i</span>, Images of the same region at 400 µm depth <span class="caption">h</span> before and <span class="caption">i</span> after subregion correction. Fluorescence intensity is improved by about 9.3-fold after correction. Insert: Zoomed-in view of the neurons pointed by the blue and red arrows. Scale bar, 5 µm.
            <span class="caption">j</span>, The correction masks for four subregions used to capture image <span class="caption">i</span>.
            <span class="caption">k</span>, Comparison of the intensity profile of representative neurons (pointed by the blue arrow in <span class="caption">e</span> and the red arrow in <span class="caption">f</span>) at 250 µm depth before (blue line) and after (red line) correction.
            <span class="caption">l</span>, Comparison of the intensity profile of representative neurons (indicated by the blue arrow in <span class="caption">h</span> and the red arrow in <span class="caption">i</span>) at 400 µm depth before (blue line) and after correction (red line).
          </p>
          <!-- </a>
          <p class="caption">
            <strong>3D RI reconstruction of a thin layer of live MDCK Cells sample.</strong>
          </p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI distribution of MDCK cells within a 358.4 × 358.4 × 44 μm<sup>3</sup> volume. The RI of the cells ranges between 1.33 to 1.36. 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images. 
            <span class="caption">c</span>, Zoomed-in views of the highlighted region: the measured image (top), the predicted image (middle), and the error map between the measured and predicted images (bottom). 
            <span class="caption">d</span>, Schematic diagram of the optical setup of FDT. Fluorescence is excited by scanning a focus with a spatial light modulator (SLM), and diffracted fluorescence images are captured in reflection mode using a camera. 
            <span class="caption">e-g</span>, Cross-sectional views of the RI distribution of MDCK cells on three representative planes that are 12.5 μm apart, showing optical sectioning ability and high 3D resolution. 
            <span class="caption">h</span>, Zoomed-in view of the image <i>z</i>-stack of cells in the highlighted region in <span class="caption">e</span>. The <i>z</i>-position of each image is labeled on the <i>z</i> axis below the images. The images again highlight the optical sectioning and high resolution of FDT.
          </p> -->
        </div>  
        <div class="columns is-centered">

        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Z Stack Video of neuron</h3>
  <!--           <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p> -->
              <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/ri_mdck_z~1.mp4"
                      type="video/mp4"> 
            </video> -->
            <a href="">
            <img src="./static/videos/12-18-23 tdTomato PV whole brain in vitro I1_45.gif">
          </a>
          </div>
        </div>
          
        <!--/ Visual Effects. -->
  
        <!-- Matting. -->
   <!--      <div class="column">
          <div class="content">
          <h3 class="title is-4">3D view</h3>
          <div class="columns is-centered">
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
     <!--            <video id="dollyzoom" autoplay controls muted loop playsinline height="95%">
                <source src="./static/videos/ri_mdck_3d720.mp4"
                        type="video/mp4">
              </video>
            </div>
  
          </div>
        </div> -->
      </div>  




        <p>
        </p>
        <p>
        </p>
        <div class="work-item">
          <h3 class="title is-4">Imaging cerebral blood vessels deep in the mouse brain</h3>
          <a href="">
            <img src="./static/images/Fig5.jpg" >
          </a>
          <p class="caption">
            <strong>Imaging blood vessels with intravascular fluorophore injection deep in the mouse brain using 2P-FOCUS. </strong>
          </p>
          <p>
            <span class="caption">a</span>, Volumetric view of cerebral blood vessels with intravascular FITC-dextran injection, imaged by 2P-FOCUS ex vivo. The image volume is 230 × 230 × 510 μm<sup>3</sup>. 
            <span class="caption">b</span>, Maximum intensity projection (MIP) of the top 100 μm-thick volume along the <i>z</i> axis.
            <span class="caption">c</span>, MIP of the bottom 100 μm-thick volume along the <i>z</i> axis.
            <span class="caption">d</span>, Two-photon image of blood vessels at 340 μm depth without correction. All pixels of the DMD are turned on. The illumination power on the sample is 19 mW. The peak fluorescence intensity is 27.
            <span class="caption">e</span>, Image of the same region as in <span class="caption">d</span> after subregion correction. The illumination power on the sample is the same as in <span class="caption">d</span> at 19 mW, but the peak fluorescence intensity is improved by 30.6-fold, reaching 826.
            <span class="caption">f-g</span>, Zoomed-in view of the regions in the dashed box in <span class="caption">d-e</span>, showing that small capillaries become visible after scattering correction.
            <span class="caption">h</span>, The location of the 4 subregions on the image plane.
            <span class="caption">i</span>, The correction masks used in the experiment when acquiring image <span class="caption">e</span>. The radius of super-pixels is 4 pixels and the sparsity is 0.4.
            <span class="caption">j</span>, Comparison of the fluorescence intensity profile before (yellow line) and after (red line) correction along the dashed line in <span class="caption">f-g</span>. The intensity profile of the case before correction is magnified by 10 times for display purposes.
          </p>
        </div>

        <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Z Stack Video of FITC blood vessles</h3>
  <!--           <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p> -->
           <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100% style="margin-top: 20px;">
              <source src="./static/videos/3dtube0721_11.mp4"
                      type="video/mp4">
            </video> -->

            <a href="">
            <img src="./static/videos/12-19-23 FITC blood vessel whole brain in vitro I6.gif">
          </a>
          </div>
        </div>  
          </div>
  
        <!--/ Visual Effects. -->
  
        <!-- Matting. -->
  <!--       <div class="column">
          <div class="content">
          <h3 class="title is-4">Radial Rotational Perspective</h3>
          <div class="columns is-centered">  -->
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
 <!--              <video id="matting-video" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/3dtube0721_2.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        </div> -->
        
      <!--  <div class="columns is-centered"> -->
        <!-- Matting. -->
       <!-- <div class="column">
          <div class="content">
          <h3 class="title is-4">Radial Rotational Perspective</h3>
          <div class="columns is-centered"> -->
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
              <!--   <video id="matting-video" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/ri_3dtube_z~2.mp4"
                        type="video/mp4">
              </video> -->
       <!--      </div>
          </div>
        </div>
        </div>
        
      </div>  -->



        
      </div>
    </div>
  </div>
</div>

<style>
  .related-work {
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  .work-item {
    text-align: center;
    margin-bottom: 20px;
    width: 100%;
  }
  .work-item img {
    display: block;
    margin: 0 auto;
    width: 100%;
    height: auto;
  }
  .caption {
    font-weight: bold;
    margin-top: 10px;
  }
</style>
</div>

<div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      
    
    <!-- Concurrent Work. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

    <!-- Animation. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
<!--         <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        
<!--         <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p> -->
        
        <!--/ Re-rendering.

      </div>
    </div>
    <!--/ Animation. -->

  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zepeda2024scatteringcompensationfourierdomainopenchannel,
      title={Scattering compensation through Fourier-domain open-channel coupling in two-photon microscopy}, 
      author={Daniel Zepeda and Yucheng Li and Yi Xue},
      year={2024},
      eprint={2401.15192},
      archivePrefix={arXiv},
      primaryClass={physics.optics},
      url={https://arxiv.org/abs/2401.15192}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
