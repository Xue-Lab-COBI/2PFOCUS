<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy">
  <meta name="keywords" content="Scattering correction, Open channel, Two-photon microscopy, Deep tissue imaging">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
 
    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon2.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
<!--   <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .column.content img {
      width: 100%;
      height: auto;
    }
    .caption {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text {
      font-weight: bold;
      margin-top: 10px;
    }
    .caption-text .section-title {
      font-weight: bold;
      font-style: italic;
    }
    .scientific-notation {
      font-family: 'Times New Roman', Times, serif;
      font-style: italic;
    }
    .superscript {
      vertical-align: super;
      font-size: smaller;
    }
  </style>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scattering Correction through Fourier-Domain Open-Channel Coupling in Two-Photon Microscopy</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Daniel Zepeda</a>,</span>
            <span class="author-block">
              <a href="">Yucheng Li</a>,</span>
            <span class="author-block">
              <a href="https://cobi.ucdavis.edu/people">Yi Xue*</a>,
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of California, Davis,</span>
<!--             <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.15192"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="http://arxiv.org/abs/2401.15192"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> 
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->




<section class="section">



  
  <div class="container is-max-desktop">
    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Light penetration depth in biological tissue is limited by tissue scattering. Correcting scattering becomes particularly challenging in scenarios with limited photon availability and when access to the transmission side of the scattering tissue is not possible. 
          </p>
          <p>  
            Here, we introduce a new two-photon microscopy system with Fourier-domain open-channel coupling for scattering correction (2P-FOCUS). 2P-FOCUS corrects scattering by intensity modulation in the Fourier domain, leveraging the nonlinearity of multiple-beam interference and two-photon excitation, eliminating the need for a guide star, iterative optimization, or measuring transmission or reflection matrices. 2P-FOCUS can also correct scattering beyond the limitation of the memory effect by automatically customizing correction masks for each subregion in a large field-of-view. 
          </p>
          <p>  
            We provide several proof-of-principle demonstrations here, including focusing and imaging through a bone sample, and imaging neurons and cerebral blood vessels in the mouse brain ex vivo. 2P-FOCUS significantly enhances two-photon fluorescence signals by several tens of folds compared to cases without scattering correction at the same excitation power. 2P-FOCUS can also correct tissue scattering over a 230 x 230 x 500 Âµm<span class="superscript">3</span> volume, which is beyond the memory effect range. 2P-FOCUS is able to measure, calculate, and correct scattering within a few seconds, effectively delivering more light deep into the scattering tissue. 2P-FOCUS could be broadly adopted for deep tissue imaging owing to its powerful combination of effectiveness, speed, and cost.

          </p>
        </div>
      </div>
    </div>
    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Overview</h2>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/Fig1.pdf" alt="Matting Example" style="width: 100%; height: auto;">
            <p class="caption">
              <strong>Overview of 2P-Focus Principle and schematic diagram</strong>
            </p>
            <p>
              <span class="caption">a</span>, Without correction, all pixels of the digital micromirror device (DMD) are turned on, allowing all incident light to pass through to the scattering sample. The incident light is scattered and cannot form a tight focus. 
              <span class="caption">b</span>, The process of generating a correction mask involves three steps. The first step is to project random intensity patterns, which are orthogonal to each other, onto the DMD and record the corresponding fluorescence intensity using a photomultiplier tube (PMT). The second step is selecting the random masks that correspond to high fluorescence intensity and summing these masks to create a grayscale correction mask. The third step is to binarize the grayscale correction mask for display on the DMD. 
              <span class="caption">c</span>, With correction, the binary correction mask is projected on the DMD, allowing only the beams that interfere constructively pass through. The illumination power on the sample is maintained at the same level before and after correction by increasing the input power to the DMD to compensate for the power loss due to turning off some pixels. The correction results in a brighter focus compared to the case before correction. 
              <span class="caption">d</span>, Optical schematic diagram of 2P-FOCUS. A femtosecond laser at 1035 nm is used as the light source. A half-wave plate (HWP) and a polarized beam splitter (PBS) are used to control the laser power. A pair of scanning mirrors (SM) is used to scan the focus across the field-of-view. A grating is used to compensate for the spatial dispersion caused by the DMD. Three 4-<i>f</i> systems are implemented with pairs of relay lenses (L1 and L2, L3 and L4, L5 and the tube lens). DMD is located on the conjugate plane of the objective lens's (OL) back aperture. The objective lens focuses the beams on the sample and collects emitted fluorescence. Fluorescence is detected by a PMT after passing through a dichroic mirror (DM), a collection lens, and a color filter. Sample is mounted on a linear translation stage for collecting z-stack images
            </p>

          </div>
        </div>
      </div>
      
      <style>
        .column.content img {
          width: 100%;
          height: auto;
        }
      </style>
    </div>

    <!--/ Matting. -->



<div class="columns is-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Results</h2>

    <div class="content has-text-justified">
      <p>
        We demonstrate the performance of 2P-FOCUS with proof-of-principle experiments, including focusing and imaging through approximately 200 Î¼m-thick bone,
        and imaging fluorescence-labeled neurons and blood vessels up to 500 Î¼m deep in the mouse brain ex vivo. 2P-FOCUS achieves a 3-60 fold enhancement in fluorescence intensity
        compared to standard two-photon microscopy. 2P-FOCUS can also correct scattering beyond the memory effect range by projecting different correction masks onto corresponding subregions, achieving a 230 Ã 230 Î¼m<sup>2</sup> field-of-view in all the experiments. 
        2P-FOCUS completes the entire correction process in a few seconds, including taking measurements, calculating correction masks, and projecting correction masks. 2P-FOCUS is an active scattering correction tool for focusing and imaging through highly scattering tissues.
      </p>
      <div class="related-work">
        <h3 class="title is-4">Imaging fluorescence beads through a 200 Î¼m-thick bone beyond the memory effect range.</h3>
        <div class="work-item">
          <a href="">
            <img src="./static/images/fig_ucd3.jpg">
          </a>
          <p class="caption">
            <strong>Reconstruction of the 3D RI of a simulated "UCDavis" pattern.</strong>
          </p>
          <p>
            <span class="caption">a</span>, Reconstructed 3D RI distribution of the "UCDavis" pattern in 3D from 400 fluorescence images. 
            <span class="caption">b</span>, A representative ground-truth (GT) image, generated using the multi-slice model with the ground-truth 3D RI, where the RI of the letters is 1.38 and the background is 1.33. 
            <span class="caption">c</span>, The predicted fluorescence image under the same illumination as <span class="caption">b</span> with the reconstructed 3D RI. 
            <span class="caption">d</span>, Zoomed-in views of the regions within the orange and green boxes in <span class="caption">b</span> and <span class="caption">c</span>, respectively. The SSIM and PSNR between the ground-truth and predicted images are 0.9994 and 56.9062, respectively. 
            <span class="caption">e</span>, Results of self-calibration of the positions of fluorescent sources at 50, 100, and 150 iterations. The blue circle indicates the irradiated region from the ground-truth position of the excited fluorophore, and the white dashed line indicates the irradiated region from the predicted position of the fluorophore. 
            <span class="caption">f</span>, The plot on the right shows the MSE loss between the self-calibrated and ground-truth fluorophore positions, converging to 0.001 within 500 iterations, indicating successful self-calibration of the positions of fluorescent sources. 
            <span class="caption">g</span>, Comparison of the ground-truth RI (top row) and the predicted RI (bottom row) on each <i>z</i>-plane, as indicated by the axis below. 
            <span class="caption">h</span>, Effect of the coarse-to-fine structure on reconstruction results on two different <i>z</i>-planes (top row, <i>z</i> = 65 Î¼m; bottom row, <i>z</i> = 53 Î¼m). The first three columns show results of the coarse-to-fine structure at different iterations (100, 200, and 300) with progressively increasing sampling grid at 128 Ã 128, 256 Ã 256, and 512 Ã 512 pixels. The last column shows the results after 300 iterations without the coarse-to-fine structure at a sampling grid of 512 Ã 512 pixels. Comparing the third column and the fourth column, the coarse-to-fine structure mitigates crosstalk between <i>z</i>-planes and reconstructs the missing low-frequency signals.
          </p>
        </div>
        
        
        <div class="work-item">
          <h3 class="title is-4">MDCK</h3>
          <a href="">
            <img src="./static/images/fig_mdck3.jpg" alt="D-NeRF">
          </a>
<!--           <p class="caption">3D RI Reconstruction of a thin sample of live MDCK cells.</p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI distribution within a volume of 358.4 x 358.4 x 60 Âµm<span class="superscript">3</span> . 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images, with a highlighted region of interest. 
            <span class="caption">c</span>, Detailed views of the highlighted region: measured image (top), predicted image (middle), and error map (bottom). 
            <span class="caption">d-f</span>, Cross-sectional views of the RI difference  distribution along different planes (xy, xz, yz), illustrating spatial variations in RI. 
            <span class="caption">g</span>, Quantitative analysis of RI variation of the red box in <span class="caption">d</span>, showing RI along the X-axis (top) and Z-axis (bottom). 
            <span class="caption">h</span>, Sequence of images highlighting the appearance and disappearance of specific features within the region along the Z-axis.
          </p> -->
          </a>
          <p class="caption">
            <strong>3D RI reconstruction of a thin layer of live MDCK Cells sample.</strong>
          </p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI distribution of MDCK cells within a 358.4 Ã 358.4 Ã 44 Î¼m<sup>3</sup> volume. The RI of the cells ranges between 1.33 to 1.36. 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images. 
            <span class="caption">c</span>, Zoomed-in views of the highlighted region: the measured image (top), the predicted image (middle), and the error map between the measured and predicted images (bottom). 
            <span class="caption">d</span>, Schematic diagram of the optical setup of FDT. Fluorescence is excited by scanning a focus with a spatial light modulator (SLM), and diffracted fluorescence images are captured in reflection mode using a camera. 
            <span class="caption">e-g</span>, Cross-sectional views of the RI distribution of MDCK cells on three representative planes that are 12.5 Î¼m apart, showing optical sectioning ability and high 3D resolution. 
            <span class="caption">h</span>, Zoomed-in view of the image <i>z</i>-stack of cells in the highlighted region in <span class="caption">e</span>. The <i>z</i>-position of each image is labeled on the <i>z</i> axis below the images. The images again highlight the optical sectioning and high resolution of FDT.
          </p>
        </div>
        <div class="columns is-centered">

        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h3 class="title is-4">2D view</h3>
  <!--           <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p> -->
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/ri_mdck_z~1.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Visual Effects. -->
  
        <!-- Matting. -->
        <div class="column">
          <div class="content">
          <h3 class="title is-4">3D view</h3>
          <div class="columns is-centered">
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
              <video id="dollyzoom" autoplay controls muted loop playsinline height="95%">
                <source src="./static/videos/ri_mdck_3d720.mp4"
                        type="video/mp4">
              </video>
            </div>
  
          </div>
        </div>
      </div>




        <p>
        </p>
        <p>
        </p>
        <div class="work-item">
          <h3 class="title is-4">3D tube</h3>
          <a href="">
            <img src="./static/images/fig_tube3.jpg" alt="NR-NeRF">
          </a>
          <p class="caption">
            <strong>3D RI reconstruction of a 3D cultured bovine myotube.</strong>
          </p>
          <p>
            <span class="caption">a</span>, 3D visualization of the RI of 3D cultured bovine myotube within a volume of 530 Ã 530 Ã 300 Î¼m<sup>3</sup>. 
            <span class="caption">b</span>, Comparison of the measured (top) and predicted (bottom) images. 
            <span class="caption">c-d</span>, Cross-sectional views of the reconstructed RI on two representative planes, showing high resolution and optical sectioning ability. 
            <span class="caption">e</span>, Zoomed-in details of the highlighted regions in <span class="caption">d</span>, labeled by corresponding colors, showing different morphologies of the 3D cultured bovine myotube during proliferation and differentiation. The results indicate that FDT can accurately reconstruct various structures across a wide range of spatial frequencies. See the video in the supplementary material for a better 3D visualization.
          </p>
        </div>

        <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <h3 class="title is-4">Axial Rotational Perspective</h3>
  <!--           <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p> -->
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100% style="margin-top: 20px;">
              <source src="./static/videos/3dtube0721_11.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Visual Effects. -->
  
        <!-- Matting. -->
        <div class="column">
          <div class="content">
          <h3 class="title is-4">Radial Rotational Perspective</h3>
          <div class="columns is-centered">
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
              <video id="matting-video" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/3dtube0721_2.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        </div>
        
        <div class="columns is-centered">
        <!-- Matting. -->
        <div class="column">
          <div class="content">
          <h3 class="title is-4">Radial Rotational Perspective</h3>
          <div class="columns is-centered">
  <!--           <div class="column content"> -->
  <!--             <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p> -->
              <video id="matting-video" autoplay controls muted loop playsinline height="100%">
                <source src="./static/videos/ri_3dtube_z~2.mp4"
                        type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        </div>
        
      </div>



        
      </div>
    </div>
  </div>
</div>

<style>
  .related-work {
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  .work-item {
    text-align: center;
    margin-bottom: 20px;
    width: 100%;
  }
  .work-item img {
    display: block;
    margin: 0 auto;
    width: 100%;
    height: auto;
  }
  .caption {
    font-weight: bold;
    margin-top: 10px;
  }
</style>
</div>

<div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      
    
    <!-- Concurrent Work. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

    <!-- Animation. -->
<!--     <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
<!--         <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        
<!--         <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p> -->
        
        <!--/ Re-rendering.

      </div>
    </div>
    <!--/ Animation. -->

  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{he2024fluorescencediffractiontomographyusing,
      title={Fluorescence Diffraction Tomography using Explicit Neural Fields}, 
      author={Renzhi He and Yucheng Li and Junjie Chen and Yi Xue},
      year={2024},
      eprint={2407.16657},
      archivePrefix={arXiv},
      primaryClass={physics.optics},
      url={https://arxiv.org/abs/2407.16657}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
